# -*- coding: utf-8 -*-
"""Food.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1owg1f98oME4nzJTNjNq_wJfmaNMgsr3W
"""

# from google.colab import drive
# drive.mount('/content/drive')

from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, \
    Dropout
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import Model
from keras.preprocessing import image
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import load_model

from IPython.display import display, HTML
import numpy as np
import PIL
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import pandas as pd
from pathlib import Path
import os.path
import matplotlib.pyplot as plt
import seaborn as sns
import cv2

image_dir = Path('C:\CLASS\python\Rec\Indian_food')

filepaths = list(image_dir.glob(r'**\*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

images = pd.concat([filepaths, labels], axis=1)

category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(500, replace=True, random_state=1))
image_df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)

#image_df
image_df.to_pickle('C:\CLASS\python\Rec\imagef.pkl')

print(image_df['Label'].value_counts())

data_df = pd.read_pickle('C:\CLASS\python\Rec\imagef.pkl')
# data_df

train_df, test_df = train_test_split(data_df, train_size=0.7, shuffle=True, random_state=1)

train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   validation_split=0.2)
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,
                                  shear_range=0.2,
                                  zoom_range=0.2,
                                  horizontal_flip=True, )

batch_size_trainingft = 64
batch_size_validationft = 64

train_images = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=batch_size_trainingft,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=batch_size_validationft,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images = test_datagen.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=batch_size_trainingft,
    shuffle=False
)

resnet_model = Sequential()
base_model = ResNet50(include_top=False, weights='imagenet', classes=len(train_images.class_indices),
                      input_shape=(224, 224, 3), pooling='avg')
for layer in base_model.layers:
    layer.trainable = False
resnet_model.add(base_model)
resnet_model.add(Flatten())
resnet_model.add(Dense(1024, activation='relu'))
resnet_model.add(Dense(1024, activation='relu'))  # neurons
# resnet_model.add(Dropout(0.5))
resnet_model.add(Dense(len(train_images.class_indices), activation='softmax'))

resnet_model.summary()

resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
resnet_model.fit(
    train_images,
    validation_data=val_images,
    epochs=50,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=4,
            restore_best_weights=True
        )
    ]
)

results = resnet_model.evaluate(test_images, verbose=0)
print("Test Accuracy: {:.2f}%".format(results[1] * 100))

resnet_model.save('C:\CLASS\python\Rec\saved1.h5')

# # op_img = load_image('/content/drive/MyDrive/food/images/sambar/Image_124.jpg')
class_names = list(train_images.class_indices.keys())
print(class_names)
model = load_model('C:\CLASS\python\Rec\saved1.h5')

img = image.load_img('C:\CLASS\python\Rec\Indian_food\unni_appam\0ccc54dc39.jpg', target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
images = np.vstack([x])

classes = model.predict(images)
text = class_names[np.argmax(classes)]
print(text)

ingri = pd.read_csv('C:\CLASS\python\Rec\recipie.csv', index_col=False)




def pretty_print(df):
    return display(HTML(df.to_html().replace("\\r\\n", "<br>")))


pd.set_option('display.max_colwidth', None)
insr = ingri[ingri['Food'] == text]
ins = pd.DataFrame(insr['Ingridients'])
pretty_print(ins)

rec = pd.DataFrame(insr['Recipie'])
pretty_print(rec)
